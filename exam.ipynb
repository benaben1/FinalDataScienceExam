{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Final Exam\n",
    "\n",
    "# Background on Python, iPython, Jupyter and Pandas\n",
    "\n",
    "[Python](https://www.python.org/) is a high-level general purpose programming language named after a [British comedy troup](https://www.youtube.com/user/MontyPython), created by a [Dutch programmer as a hobby project](http://en.wikipedia.org/wiki/Guido_van_Rossum) and maintained by an international group of friendly but opinionated python enthusiasts (`import this!`). Until June 2018, Guido van Rossum was the [Benevolent dictator for life](https://en.wikipedia.org/wiki/Benevolent_dictator_for_life) for the Python language, now decisions are made jointly by the Python Steering Council.\n",
    "\n",
    "Python is popular for data science because it's powerful, fast, plays well with others, runs everywhere, is easy to learn, highly readable, and open. Because it's general purpose it can be used for full-stack development. It's got a growing list of useful libraries for scientitic programming, data manipulation, data analysis. (Numpy, Scipy, Pandas, Scikit-Learn, Statsmodels, Matplotlib, Pybrain, etc.)\n",
    "\n",
    "[iPython](http://ipython.org/) is an enhanced, interactive python interpreter started as a grad school project by [Fernando Perez](http://fperez.org/). iPython (jupyter) notebooks allow you to run a multi-language (Python, R, Julia, Markdown, LaTex, etc) interpreter in your browser to create rich, portable, and sharable code documents.\n",
    "\n",
    "[Pandas](http://pandas.pydata.org/) is a libary created by [Wes McKinney](http://blog.wesmckinney.com/) that introduces the R-like dataframe object to Python and makes working with data in Python a lot easier. It's also a lot more efficient than the R dataframe and pretty much makes Python superior to R in every imaginable way (except for ggplot 2). \n",
    "\n",
    "\n",
    "# Final Exam\n",
    "\n",
    "This self-grading notebook serves as a final exam for the introductory course.\n",
    "If you have grasped the contents of the course, you should be able to complete\n",
    "this exam. \n",
    "\n",
    "It is essential that you answer each cell by assigning the solution to `QUESTION_#`\n",
    "where `#` is the question number.  \n",
    "\n",
    "We will start with a warm-up question that is already answered.\n",
    "\n",
    "## Getting started with Jupyter (iPython) Notebooks\n",
    "\n",
    "To start up a Jupyter notebook server, simply navigate to the directory where you want the notebooks to be saved and run the command\n",
    "\n",
    "```\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "A browser should open with a notebook navigator. Click the \"New\" button and select \"Python 3\".\n",
    "\n",
    "A beautiful blank notebook should open in a new tab\n",
    "\n",
    "Name the notebook by clicking on \"Untitled\" at the top of the page.\n",
    "\n",
    "Notebooks are squences of cells. Cells can be markdown, code, or raw text. Change the first cell to markdown and briefly describe what you are going to do in the notebook. \n",
    "\n",
    "## Getting started with Pandas\n",
    "\n",
    "We start by importing the libraries we're going to use any library in the notebook:E.G., `pandas` and `matplotlib`, `seaborn`, `Numpy`, `Statsmodels`\n",
    "\n",
    "\n",
    "\n",
    "## Question 0\n",
    "\n",
    "Create a 3-element 1-dimensional array containing the values [1,1,1]\n",
    "\n",
    "_Note_: This answer is not assessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Setup: The solution is used as a model\n",
    "\n",
    "QUESTION_0 = np.ones(3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Documentation with ``?``\n",
    "\n",
    "The Python language and its data science ecosystem is built with the user in mind, and one big part of that is access to documentation.\n",
    "Every Python object contains the reference to a string, known as a *doc string*, which in most cases will contain a concise summary of the object and how to use it.\n",
    "Python has a built-in ``help()`` function that can access this information and prints the results.\n",
    "For example, to see the documentation of the built-in ``len`` function, you can do the following:\n",
    "\n",
    "```ipython\n",
    "In [1]: help(len)\n",
    "Help on built-in function len in module builtins:\n",
    "\n",
    "len(...)\n",
    "    len(object) -> integer\n",
    "    \n",
    "    Return the number of items of a sequence or mapping.\n",
    "```\n",
    "\n",
    "Depending on your interpreter, this information may be displayed as inline text, or in some separate pop-up window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data into a Pandas DataFrame\n",
    "\n",
    "So far we've been working with many datasets and raw files during our class sessions. This functions below should be familiar for your to apply through out the exam\n",
    "\n",
    "Built-in Data Structures\n",
    "- strings \"\"\n",
    "- lists []\n",
    "- tuples ()\n",
    "- sets {}\n",
    "- dictionaries {'key':value}\n",
    "\n",
    "Additional Essential Data Structures\n",
    "\n",
    "- numpy arrays ([])\n",
    "- pandas Series\n",
    "- pandas DataFrame\n",
    "- tensorflow Tensors\n",
    "\n",
    "\n",
    "Today we'll primarily be working with the pandas DataFrame. The pandas DataFrame is a two-dimensional size-mutable, potentially heterogeneous tabular data structure with labeled axes. It's basically a spreadsheet you can program and it's an incredibly useful Python object for data analysis. \n",
    "\n",
    "You can load data into a dataframe using Pandas' excellent `read_*` functions.\n",
    "\n",
    "We're going to try two of them: read_table & read_csv\n",
    "\n",
    "Pro tip: TAB COMPLETION!\n",
    "\n",
    "Pro tip: jupyter will pull the doc string for a command just by asking it a question.\n",
    "\n",
    "Pro tip: jupyter will give you the allowable arguments if you hit `shift + tab`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Question 1 (a) (i)\n",
    "\n",
    "Construct the correlation matrix\n",
    "\n",
    "$$\\left[\\begin{array}{ccc} 1 & 0.2 & 0.5 \\\\ 0.2 & 1 & 0.8 \\\\ 0.5 & 0.8 & 1 \\end{array}\\right]$$\n",
    "\n",
    "as a NumPy array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.99053606, -0.70463404],\n",
       "       [-0.99053606,  1.        ,  0.79535595],\n",
       "       [-0.70463404,  0.79535595,  1.        ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data =([1,0.2,0.5], [0.2,1,0.8], [0.5,0.8,1])\n",
    "\n",
    "np.corrcoef(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (ii)\n",
    " Construct the correlation matrix\n",
    "\n",
    "$$\\left[\\begin{array}{ccc} 1 & 0.2 & 0.5 \\\\ 0.2 & 1 & 0.8 \\\\ 0.5 & 0.8 & 1 \\end{array}\\right]$$\n",
    "\n",
    "as a DataFrame with columns and index both equal to `['A', 'B', 'C']`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C\n",
      "0  1.0  0.2  0.5\n",
      "1  0.2  1.0  0.8\n",
      "2  0.5  0.8  1.0\n"
     ]
    }
   ],
   "source": [
    "#  creating a DataFrame in order to capture the above dataset in Python:\n",
    "import pandas as pd\n",
    "\n",
    "data = {'A': [1,0.2,0.5],\n",
    "        'B': [0.2,1,0.8],\n",
    "        'C': [0.5,0.8,1]\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(data,columns=['A','B','C'])\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B         C\n",
      "A  1.000000 -0.990536 -0.704634\n",
      "B -0.990536  1.000000  0.795356\n",
      "C -0.704634  0.795356  1.000000\n"
     ]
    }
   ],
   "source": [
    "# create a correlation matrix \n",
    "df.corr()\n",
    "data = {'A': [1,0.2,0.5],\n",
    "        'B': [0.2,1,0.8],\n",
    "        'C': [0.5,0.8,1]\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(data,columns=['A','B','C'])\n",
    "\n",
    "corrMatrix = df.corr()\n",
    "print (corrMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (iii) \n",
    "\n",
    "Load the momentum data in the CSV file `momentum.csv`, set the column `date` \n",
    "as the index, and ensure that `date` is a `DateTimeIndex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date  mom_01  mom_02  mom_03  mom_04  mom_05  mom_06  mom_07  \\\n",
      "0    2016-01-04    0.67   -0.03   -0.93   -1.11   -1.47   -1.66   -1.40   \n",
      "1    2016-01-05   -0.36    0.20   -0.37    0.28    0.16    0.18   -0.22   \n",
      "2    2016-01-06   -4.97   -2.33   -2.60   -1.16   -1.70   -1.45   -1.15   \n",
      "3    2016-01-07   -4.91   -1.91   -3.03   -1.87   -2.31   -2.30   -2.70   \n",
      "4    2016-01-08   -0.40   -1.26   -0.98   -1.26   -1.13   -1.02   -0.96   \n",
      "..          ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "498  2017-12-22    0.24    0.13   -0.07   -0.01   -0.08   -0.10   -0.14   \n",
      "499  2017-12-26    0.89    0.70    0.23   -0.03    0.10   -0.06   -0.14   \n",
      "500  2017-12-27   -0.58   -0.55   -0.27   -0.19   -0.14    0.18    0.18   \n",
      "501  2017-12-28    0.14    0.23    0.32    0.02    0.29    0.16    0.30   \n",
      "502  2017-12-29   -0.42   -0.61   -0.48   -0.57   -0.45   -0.41   -0.52   \n",
      "\n",
      "     mom_08  mom_09  mom_10  \n",
      "0     -2.08   -1.71   -2.67  \n",
      "1      0.25    0.29    0.13  \n",
      "2     -1.46   -1.14   -0.45  \n",
      "3     -2.31   -2.36   -2.66  \n",
      "4     -1.42   -0.94   -1.32  \n",
      "..      ...     ...     ...  \n",
      "498   -0.16   -0.05   -0.01  \n",
      "499   -0.07    0.14   -0.65  \n",
      "500    0.10    0.22    0.36  \n",
      "501    0.15    0.28    0.29  \n",
      "502   -0.45   -0.70   -0.94  \n",
      "\n",
      "[503 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Loading the momentum data in the CSV file\n",
    "import pandas as pd\n",
    "data = pd.read_csv('momentum(1).csv')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            mom_01  mom_02  mom_03  mom_04  mom_05  mom_06  mom_07  mom_08  \\\n",
      "date                                                                         \n",
      "2016-01-04    0.67   -0.03   -0.93   -1.11   -1.47   -1.66   -1.40   -2.08   \n",
      "2016-01-05   -0.36    0.20   -0.37    0.28    0.16    0.18   -0.22    0.25   \n",
      "2016-01-06   -4.97   -2.33   -2.60   -1.16   -1.70   -1.45   -1.15   -1.46   \n",
      "2016-01-07   -4.91   -1.91   -3.03   -1.87   -2.31   -2.30   -2.70   -2.31   \n",
      "2016-01-08   -0.40   -1.26   -0.98   -1.26   -1.13   -1.02   -0.96   -1.42   \n",
      "...            ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "2017-12-22    0.24    0.13   -0.07   -0.01   -0.08   -0.10   -0.14   -0.16   \n",
      "2017-12-26    0.89    0.70    0.23   -0.03    0.10   -0.06   -0.14   -0.07   \n",
      "2017-12-27   -0.58   -0.55   -0.27   -0.19   -0.14    0.18    0.18    0.10   \n",
      "2017-12-28    0.14    0.23    0.32    0.02    0.29    0.16    0.30    0.15   \n",
      "2017-12-29   -0.42   -0.61   -0.48   -0.57   -0.45   -0.41   -0.52   -0.45   \n",
      "\n",
      "            mom_09  mom_10  \n",
      "date                        \n",
      "2016-01-04   -1.71   -2.67  \n",
      "2016-01-05    0.29    0.13  \n",
      "2016-01-06   -1.14   -0.45  \n",
      "2016-01-07   -2.36   -2.66  \n",
      "2016-01-08   -0.94   -1.32  \n",
      "...            ...     ...  \n",
      "2017-12-22   -0.05   -0.01  \n",
      "2017-12-26    0.14   -0.65  \n",
      "2017-12-27    0.22    0.36  \n",
      "2017-12-28    0.28    0.29  \n",
      "2017-12-29   -0.70   -0.94  \n",
      "\n",
      "[503 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# set the column date as the index\n",
    "data.set_index('date', inplace=True)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (iv) ##\n",
    "\n",
    "(a). Construct a DataFrame using the data loaded in the previous question 1 (iii)\n",
    "that contains the returns from momentum portfolio 5 in March and April 2016.\n",
    "\n",
    "(b). Load another data in the csv file `crimes.csv`and modify it into a dataframe using:\n",
    "\n",
    "HINT:Notice that that has some issues when it comes to column names. Your are required to fix the issues by editing, monipulating and probably deleting some clumns columns.: \n",
    "\n",
    "The expected solutions and cleaned data should implement: \n",
    "\n",
    "1. Remove white spaces\n",
    "\n",
    "2. Replacing spaces with underscore\n",
    "\n",
    "3. You should also remove the double occurence of \"_\" in DATE__OF_OCCURENCE. Do so below:\n",
    "\n",
    "4. Write code to drop column 'Location':\n",
    "\n",
    "5. Once cleaned, we would like you to describe the better global view of the dataset. By writing code to describe, generate a sum (of null). \n",
    "\n",
    "6. Select and subsett in pandas using: `''` or quote methods or .head methods on PRIMARY_DESCRIPTION column\n",
    "\n",
    "7. Obtain the value counts for PRIMARY_DESCRIPTION column\n",
    "\n",
    "8. selecting two columns: enter code to select two columns. It will look something like: dataframe[[column 1, column 2]] for \n",
    "'PRIMARY_DESCRIPTION', 'SECONDARY_DESCRIPTION']] and view only the few columns (first ten),then subset by row index also for the first ten (3:10)\n",
    "\n",
    "9. Data Sorting: Write code to sort values for theft column according to the date of occurance, in ascending and make use of inplace function argument. `HINT: You may realise that the something is not right especially the way the sort function is sorting the data. If your are convinced by this statement. Ensure that the date objects are handled well`. \n",
    "\n",
    "10. Finally apply `Functions to series` use `Group by` year and month to look at data on a month to month basis.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1st   2nd   3rd   4th   5th   6th   7th   8th   9th  10th  ...  13th  \\\n",
      "0  2.61  0.58  0.71  0.73  0.63 -1.97  0.34  0.00  2.08 -0.09  ...  0.68   \n",
      "1  0.39 -0.08 -1.09  1.49 -1.51  0.10  0.00  1.37  1.64 -0.08  ...  0.25   \n",
      "\n",
      "   14th  15th  16th  17th  18th  19th  20th  21st  22nd  \n",
      "0  0.87  0.20 -0.11 -1.11 -0.21 -0.05  0.98  0.69 -0.17  \n",
      "1  0.73 -0.37  0.51 -0.29  0.35 -1.04 -1.33 -1.43  0.00  \n",
      "\n",
      "[2 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# DataFrame using the data loaded in the previous question 1 (iii)that contains the returns from momentum portfolio 5 in March and April 2016.\n",
    "import pandas as pd\n",
    "\n",
    "dat = {'1st': [2.61,0.39],\n",
    "        '2nd':[0.58,-0.08],\n",
    "       '3rd':[0.71,-1.09],\n",
    "       '4th':[0.73,1.49],\n",
    "       '5th':[0.63,-1.51],\n",
    "       '6th':[-1.97,0.1],\n",
    "       '7th':[0.34,0],\n",
    "       '8th':[0,1.37],\n",
    "       '9th':[2.08,1.64],\n",
    "       '10th':[-0.09,-0.08],\n",
    "       '11th':[-0.04,-0.7],\n",
    "       '12th':[0.61,0.1],\n",
    "       '13th':[0.68,0.25],\n",
    "       '14th':[0.87,0.73],\n",
    "       '15th':[0.2,-0.37],\n",
    "       '16th':[-0.11,0.51],\n",
    "       '17th':[-1.11,-0.29],\n",
    "       '18th':[-0.21,0.35],\n",
    "       '19th':[-0.05,-1.04],\n",
    "       '20th':[0.98,-1.33],\n",
    "       '21st':[0.69,-1.43],\n",
    "       '22nd':[-0.17,0]\n",
    " \n",
    "      \n",
    "        }\n",
    "df = pd.DataFrame(dat,columns=['1st','2nd','3rd','4th','5th','6th','7th','8th','9th',\n",
    "                               '10th','11th','12th','13th','14th','15th','16th','17th','18th','19th','20th','21st', '22nd'])\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           CASE#     DATE  OF OCCURRENCE                   BLOCK  IUCR  \\\n",
      "0       JB241987  04/28/2018 10:05:00 PM        009XX N LONG AVE  2092   \n",
      "1       JA430240  09/06/2017 01:30:00 PM         032XX W 26TH ST  0810   \n",
      "2       JB241350  04/28/2018 08:00:00 AM         008XX E 53RD ST  1320   \n",
      "3       JB245397  04/28/2018 09:00:00 AM    062XX S MICHIGAN AVE  0820   \n",
      "4       JB241444  04/28/2018 12:15:00 PM      046XX N ELSTON AVE  0890   \n",
      "...          ...                     ...                     ...   ...   \n",
      "261959  JA385552  08/10/2017 10:30:00 AM         048XX W IOWA ST  1310   \n",
      "261960  JA492228  10/30/2017 04:00:00 PM  072XX S SOUTH SHORE DR  0810   \n",
      "261961  JA390514  08/13/2017 08:00:00 PM    039XX W VAN BUREN ST  0910   \n",
      "261962  JA385930  08/10/2017 04:00:00 AM     071XX S WOLCOTT AVE  1305   \n",
      "261963  JA536019  12/02/2017 08:00:00 PM     083XX S INDIANA AVE  1320   \n",
      "\n",
      "        PRIMARY DESCRIPTION           SECONDARY DESCRIPTION  \\\n",
      "0                 NARCOTICS  SOLICIT NARCOTICS ON PUBLICWAY   \n",
      "1                     THEFT                       OVER $500   \n",
      "2           CRIMINAL DAMAGE                      TO VEHICLE   \n",
      "3                     THEFT                  $500 AND UNDER   \n",
      "4                     THEFT                   FROM BUILDING   \n",
      "...                     ...                             ...   \n",
      "261959      CRIMINAL DAMAGE                     TO PROPERTY   \n",
      "261960                THEFT                       OVER $500   \n",
      "261961  MOTOR VEHICLE THEFT                      AUTOMOBILE   \n",
      "261962      CRIMINAL DAMAGE             CRIMINAL DEFACEMENT   \n",
      "261963      CRIMINAL DAMAGE                      TO VEHICLE   \n",
      "\n",
      "           LOCATION DESCRIPTION ARREST DOMESTIC  BEAT  WARD FBI CD  \\\n",
      "0                      SIDEWALK      Y        N  1524  37.0     18   \n",
      "1                         OTHER      Y        N  1024  12.0     06   \n",
      "2                        STREET      N        N   233   5.0     14   \n",
      "3       RESIDENCE PORCH/HALLWAY      N        N   311  20.0     06   \n",
      "4            SMALL RETAIL STORE      N        N  1722  39.0     06   \n",
      "...                         ...    ...      ...   ...   ...    ...   \n",
      "261959                RESIDENCE      N        N  1531  37.0     14   \n",
      "261960                APARTMENT      N        Y   334   7.0     06   \n",
      "261961                   STREET      N        N  1132  24.0     07   \n",
      "261962                RESIDENCE      N        N   735  17.0     14   \n",
      "261963                   STREET      N        N   632   6.0     14   \n",
      "\n",
      "        X COORDINATE  Y COORDINATE   LATITUDE  LONGITUDE  \\\n",
      "0          1140136.0     1905903.0  41.897895 -87.760744   \n",
      "1          1155313.0     1886555.0  41.844510 -87.705519   \n",
      "2          1182892.0     1870055.0  41.798635 -87.604823   \n",
      "3          1178263.0     1863570.0  41.780946 -87.621995   \n",
      "4          1146646.0     1930549.0  41.965404 -87.736202   \n",
      "...              ...           ...        ...        ...   \n",
      "261959     1143912.0     1905538.0  41.896823 -87.746884   \n",
      "261960     1194878.0     1857803.0  41.764728 -87.561272   \n",
      "261961     1150218.0     1897735.0  41.875290 -87.723926   \n",
      "261962     1164921.0     1857378.0  41.764247 -87.671085   \n",
      "261963     1179046.0     1849699.0  41.742865 -87.619547   \n",
      "\n",
      "                             LOCATION  \n",
      "0       (41.897894893, -87.760743714)  \n",
      "1       (41.844510467, -87.705519454)  \n",
      "2       (41.798635468, -87.604823241)  \n",
      "3       (41.780946398, -87.621995369)  \n",
      "4       (41.965404069, -87.736202402)  \n",
      "...                               ...  \n",
      "261959     (41.8968233, -87.74688383)  \n",
      "261960  (41.764728045, -87.561272312)  \n",
      "261961  (41.875290412, -87.723926225)  \n",
      "261962  (41.764247182, -87.671084615)  \n",
      "261963  (41.742865052, -87.619546732)  \n",
      "\n",
      "[261964 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "# Loading csv file `crimes.csv`\n",
    "import pandas as pd\n",
    "data1 = pd.read_csv('chicago_past_year_crimes.csv')\n",
    "print(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 \n",
    "\n",
    "(a). What is the standard deviation of the data:\n",
    "\n",
    "$$ 1, 3, 1, 2,9, 4, 5, 6, 10, 4 $$\n",
    "\n",
    "**Note** Use 1 degree of freedom in the denominator.\n",
    "\n",
    "\n",
    "(b). Importing all relevant libraries \n",
    "\n",
    "`import pandas as pd, import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import math\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "import time\n",
    "import re\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import sklearn\n",
    "from tqdm import tqdm_notebook\n",
    "pd.options.mode.chained_assignment = None`. \n",
    "\n",
    "Following the same format of code below: \n",
    "\n",
    "`team_converter = pd.read_csv(\"source_files/team_converter.csv\",encoding=\"cp1252\")\n",
    "big_five_league_fixtures = pd.read_csv(\"source_files/big_five_league_fixtures.csv\")\n",
    "big_five_league_fixtures[\"date\"] = big_five_league_fixtures[\"date\"].apply(lambda x:datetime.datetime.strptime(x,\"%d/%m/%Y\").date())\n",
    "big_five_league_fixtures[\"home_points\"] = big_five_league_fixtures[\"result\"].map({\"H\":3,\"D\":1,\"A\":0})\n",
    "big_five_league_fixtures[\"away_points\"] = big_five_league_fixtures[\"result\"].map({\"A\":3,\"D\":1,\"H\":0})`\n",
    "\n",
    "`FIFA_league_season_teams_df = pd.read_csv(\"output_files/FIFA_league_season_teams_df.csv\")\n",
    "FIFA_team_season_players_df = pd.read_csv(\"output_files/FIFA_team_season_players_df.csv\")\n",
    "TM_team_managers_df = pd.read_csv(\"output_files/TM_team_managers_df.csv\")`\n",
    "\n",
    "import and load all files as specified in the code\n",
    "\n",
    "b). \n",
    "\n",
    "(i). Run the code and adjust appropriate file paths to import and convert the dataset into proper format. \n",
    "\n",
    "(ii). Join the team ids onto fixture data. HINT: Using the same conversion and format of this exmple : First line of code `FIFA_edition_dict = {\n",
    "    \"FIFA 2005\":[\"08/10/2004\",\"/fifa05_1/\"],.....}` to complete all the joins for all years. \n",
    "\n",
    "(iii). Join Manager tenure onto fixture data. \n",
    "\n",
    "(iv). Join expected points onto fixture data. \n",
    "\n",
    "(v). Create dataframe of each team's performance in each season\n",
    "\n",
    "(vi). Create dataframe of each manager tenure, with past and future performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.100179206289712"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding standard deviation\n",
    "def get_std_dev(ls):\n",
    "    n = len(ls)\n",
    "    mean = sum(ls) / n\n",
    "    var = sum((x - mean)**2 for x in ls) / (n-1) # Using 1 degree of freedom in the denominator.\n",
    "    std_dev = var ** 0.5\n",
    "    return std_dev\n",
    "\n",
    "# create a list \n",
    "ls = [1,3,1,2,9,4,5,6,10,4]\n",
    "get_std_dev(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import math\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "import time\n",
    "import re\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import sklearn\n",
    "from tqdm import tqdm_notebook\n",
    "pd.options.mode.chained_assignment = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 \n",
    "\n",
    "(a). Load the covid-19 dataset in the CSV file `COVID-19 Cases.csv`, set the column `date` as the index, and ensure that `date` is a `DateTimeIndex`. Print a view of first 10 lines of the dataset. Next we will isolate the data we want to focus our attention on by creating a new DataFrame from the source, and by applying a few filters against it. We want to isolate the records where all the following conditions are true. First the Daily Difference count is greater than zero. Next the Case Type should be Confirmed. Finally, the Country_Region should be only Italy: Check whether the results are sorted by cases & ascending order to  well and accordingly, write the command to accomplish it:\n",
    "\n",
    "(b). Now lets visually display the distribution of the values in the Difference column. We can pass an array of values into the default hist() plot (`plot the histogram using the Difference Column`):\n",
    "\n",
    "(c). Obtain descriptive and inferential statics on at least three columns & create a new DataFrame out of the three columns computed statistics on. \n",
    "\n",
    "(d). Obtain a boxplot of the selected number of columns of your choice in the dataset. Interprete the resulting chart (boxplot) to make meaning out of it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date Country_Region Province_State  Difference  \\\n",
      "0       3/9/2020          India            NaN           0   \n",
      "1       3/8/2020          India            NaN           0   \n",
      "2       3/7/2020          India            NaN           0   \n",
      "3       3/6/2020          India            NaN           0   \n",
      "4       3/5/2020          India            NaN           0   \n",
      "...          ...            ...            ...         ...   \n",
      "35497  1/27/2020          Syria            NaN           0   \n",
      "35498  1/26/2020          Syria            NaN           0   \n",
      "35499  1/25/2020          Syria            NaN           0   \n",
      "35500  1/24/2020          Syria            NaN           0   \n",
      "35501  1/23/2020          Syria            NaN           0   \n",
      "\n",
      "          Prep_Flow_Runtime Latest_Date  Case_Type  Cases        Lat  \\\n",
      "0      3/24/2020 9:39:03 AM   3/23/2020     Deaths      0  21.000000   \n",
      "1      3/24/2020 9:39:03 AM   3/23/2020     Deaths      0  21.000000   \n",
      "2      3/24/2020 9:39:03 AM   3/23/2020     Deaths      0  21.000000   \n",
      "3      3/24/2020 9:39:03 AM   3/23/2020     Deaths      0  21.000000   \n",
      "4      3/24/2020 9:39:03 AM   3/23/2020     Deaths      0  21.000000   \n",
      "...                     ...         ...        ...    ...        ...   \n",
      "35497  3/24/2020 9:39:03 AM   3/23/2020  Confirmed      0  34.802075   \n",
      "35498  3/24/2020 9:39:03 AM   3/23/2020  Confirmed      0  34.802075   \n",
      "35499  3/24/2020 9:39:03 AM   3/23/2020  Confirmed      0  34.802075   \n",
      "35500  3/24/2020 9:39:03 AM   3/23/2020  Confirmed      0  34.802075   \n",
      "35501  3/24/2020 9:39:03 AM   3/23/2020  Confirmed      0  34.802075   \n",
      "\n",
      "            Long  \n",
      "0      78.000000  \n",
      "1      78.000000  \n",
      "2      78.000000  \n",
      "3      78.000000  \n",
      "4      78.000000  \n",
      "...          ...  \n",
      "35497  38.996815  \n",
      "35498  38.996815  \n",
      "35499  38.996815  \n",
      "35500  38.996815  \n",
      "35501  38.996815  \n",
      "\n",
      "[35502 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Loading the covid-19 dataset in the CSV file \n",
    "import pandas as pd\n",
    "data = pd.read_csv('COVID-19 Cases.csv')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Country_Region Province_State  Difference     Prep_Flow_Runtime  \\\n",
      "Date                                                                        \n",
      "3/9/2020           India            NaN           0  3/24/2020 9:39:03 AM   \n",
      "3/8/2020           India            NaN           0  3/24/2020 9:39:03 AM   \n",
      "3/7/2020           India            NaN           0  3/24/2020 9:39:03 AM   \n",
      "3/6/2020           India            NaN           0  3/24/2020 9:39:03 AM   \n",
      "3/5/2020           India            NaN           0  3/24/2020 9:39:03 AM   \n",
      "...                  ...            ...         ...                   ...   \n",
      "1/27/2020          Syria            NaN           0  3/24/2020 9:39:03 AM   \n",
      "1/26/2020          Syria            NaN           0  3/24/2020 9:39:03 AM   \n",
      "1/25/2020          Syria            NaN           0  3/24/2020 9:39:03 AM   \n",
      "1/24/2020          Syria            NaN           0  3/24/2020 9:39:03 AM   \n",
      "1/23/2020          Syria            NaN           0  3/24/2020 9:39:03 AM   \n",
      "\n",
      "          Latest_Date  Case_Type  Cases        Lat       Long  \n",
      "Date                                                           \n",
      "3/9/2020    3/23/2020     Deaths      0  21.000000  78.000000  \n",
      "3/8/2020    3/23/2020     Deaths      0  21.000000  78.000000  \n",
      "3/7/2020    3/23/2020     Deaths      0  21.000000  78.000000  \n",
      "3/6/2020    3/23/2020     Deaths      0  21.000000  78.000000  \n",
      "3/5/2020    3/23/2020     Deaths      0  21.000000  78.000000  \n",
      "...               ...        ...    ...        ...        ...  \n",
      "1/27/2020   3/23/2020  Confirmed      0  34.802075  38.996815  \n",
      "1/26/2020   3/23/2020  Confirmed      0  34.802075  38.996815  \n",
      "1/25/2020   3/23/2020  Confirmed      0  34.802075  38.996815  \n",
      "1/24/2020   3/23/2020  Confirmed      0  34.802075  38.996815  \n",
      "1/23/2020   3/23/2020  Confirmed      0  34.802075  38.996815  \n",
      "\n",
      "[35502 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# set the column date as the index\n",
    "data.set_index('Date', inplace=True)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 rows of the DataFrame:\n",
      "        Date Country_Region Province_State  Difference     Prep_Flow_Runtime  \\\n",
      "0   3/9/2020          India            NaN           0  3/24/2020 9:39:03 AM   \n",
      "1   3/8/2020          India            NaN           0  3/24/2020 9:39:03 AM   \n",
      "2   3/7/2020          India            NaN           0  3/24/2020 9:39:03 AM   \n",
      "3   3/6/2020          India            NaN           0  3/24/2020 9:39:03 AM   \n",
      "4   3/5/2020          India            NaN           0  3/24/2020 9:39:03 AM   \n",
      "5   3/4/2020          India            NaN           0  3/24/2020 9:39:03 AM   \n",
      "6   3/3/2020          India            NaN           0  3/24/2020 9:39:03 AM   \n",
      "7  3/23/2020          India            NaN           3  3/24/2020 9:39:03 AM   \n",
      "8  3/22/2020          India            NaN           3  3/24/2020 9:39:03 AM   \n",
      "9  3/21/2020          India            NaN          -1  3/24/2020 9:39:03 AM   \n",
      "\n",
      "  Latest_Date Case_Type  Cases   Lat  Long  \n",
      "0   3/23/2020    Deaths      0  21.0  78.0  \n",
      "1   3/23/2020    Deaths      0  21.0  78.0  \n",
      "2   3/23/2020    Deaths      0  21.0  78.0  \n",
      "3   3/23/2020    Deaths      0  21.0  78.0  \n",
      "4   3/23/2020    Deaths      0  21.0  78.0  \n",
      "5   3/23/2020    Deaths      0  21.0  78.0  \n",
      "6   3/23/2020    Deaths      0  21.0  78.0  \n",
      "7   3/23/2020    Deaths     10  21.0  78.0  \n",
      "8   3/23/2020    Deaths      7  21.0  78.0  \n",
      "9   3/23/2020    Deaths      4  21.0  78.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('COVID-19 Cases.csv')\n",
    "#Display the first 10 rows\n",
    "result = df.head(10)\n",
    "print(\"First 10 rows of the DataFrame:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       difference  case_type country_Region\n",
      "7               3  Confirmed          Italy\n",
      "8               3  Confirmed          Italy\n",
      "10              1  Confirmed          Italy\n",
      "12              1  Confirmed          Italy\n",
      "14              1  Confirmed          Italy\n",
      "...           ...        ...            ...\n",
      "35336           4  Confirmed          Italy\n",
      "35339           2  Confirmed          Italy\n",
      "35340           1  Confirmed          Italy\n",
      "35354           1  Confirmed          Italy\n",
      "35449           1  Confirmed          Italy\n",
      "\n",
      "[5009 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# creating a new DataFrame from the source\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('COVID-19 Cases.csv')\n",
    "\n",
    "df = pd.DataFrame({'difference':df.Difference ,\n",
    "                   'case_type':df.Case_Type ,\n",
    "                   'country_Region': df.Country_Region})\n",
    "\n",
    "df_mask=df['case_type']='Confirmed'\n",
    "df_mask=df['country_Region']='Italy'\n",
    "df_mask=df['difference']>0\n",
    "filtered_df = df[df_mask]\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram of 'Difference' column\n",
    "import pandas as pd\n",
    "df = pd.read_csv('COVID-19 Cases.csv')\n",
    "df.hist(column='Difference');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         difference           lat          case\n",
      "count  35502.000000  35136.000000  35502.000000\n",
      "mean      11.103994     25.062739    162.593460\n",
      "std      167.771676     23.437435   2442.608235\n",
      "min      -62.000000    -41.454500      0.000000\n",
      "25%        0.000000     12.448525      0.000000\n",
      "50%        0.000000     31.370375      0.000000\n",
      "75%        0.000000     42.006025      1.000000\n",
      "max    14840.000000     71.706900  67800.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# descriptive statics\n",
    "\n",
    "df = pd.read_csv('COVID-19 Cases.csv')\n",
    "\n",
    "d ={'difference':(df.Difference) ,\n",
    "                   'lat':(df.Lat) ,\n",
    "                   'case':(df.Cases)}\n",
    "\n",
    "#Create a DataFrame\n",
    "df = pd.DataFrame(d)\n",
    "print(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the DataFrame:\n",
      "       Date Country_Region Province_State  Difference     Prep_Flow_Runtime  \\\n",
      "0  3/9/2020          India            NaN           0  3/24/2020 9:39:03 AM   \n",
      "1  3/8/2020          India            NaN           0  3/24/2020 9:39:03 AM   \n",
      "2  3/7/2020          India            NaN           0  3/24/2020 9:39:03 AM   \n",
      "3  3/6/2020          India            NaN           0  3/24/2020 9:39:03 AM   \n",
      "4  3/5/2020          India            NaN           0  3/24/2020 9:39:03 AM   \n",
      "\n",
      "  Latest_Date Case_Type  Cases   Lat  Long  \n",
      "0   3/23/2020    Deaths      0  21.0  78.0  \n",
      "1   3/23/2020    Deaths      0  21.0  78.0  \n",
      "2   3/23/2020    Deaths      0  21.0  78.0  \n",
      "3   3/23/2020    Deaths      0  21.0  78.0  \n",
      "4   3/23/2020    Deaths      0  21.0  78.0  \n"
     ]
    }
   ],
   "source": [
    "# inferential statics\n",
    "import pandas as pd\n",
    "df = pd.read_csv('COVID-19 Cases.csv')\n",
    "#Display the first 5 rows\n",
    "result = df.head(5)\n",
    "print(\"First 5 rows of the DataFrame:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          difference  \\\n",
      "0  0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4 ...   \n",
      "\n",
      "                                                 lat  \\\n",
      "0  0        21.000000\n",
      "1        21.000000\n",
      "2       ...   \n",
      "\n",
      "                                                case  \n",
      "0  0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4 ...  \n"
     ]
    }
   ],
   "source": [
    "#  creating a DataFrame \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('COVID-19 Cases.csv')\n",
    "\n",
    "data ={'difference':[df.Difference] ,\n",
    "                   'lat':[df.Lat] ,\n",
    "                   'case':[df.Cases]}\n",
    "\n",
    "df = pd.DataFrame(data,columns=['difference','lat','case'])\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>difference</td>\n",
       "      <td>0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lat</td>\n",
       "      <td>0        21.000000\n",
       "1        21.000000\n",
       "2       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case</td>\n",
       "      <td>0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     variable                                              value\n",
       "0  difference  0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4 ...\n",
       "1         lat  0        21.000000\n",
       "1        21.000000\n",
       "2       ...\n",
       "2        case  0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4 ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#melt data frame into long format\n",
    "df_melted = pd.melt(df)\n",
    "\n",
    "#view first 10 rows of melted data frame\n",
    "df_melted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#create seaborn boxplots by group\n",
    "sns.boxplot(x='variable', y='value', kind=\"box\", data=df_melted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "(a). Write the function `QUESTION_20` that will take a single input `s`, which is a string\n",
    "and will return a Series that counts the number of times each letter in `s` appears in `s`\n",
    "_without_ regard to case. Do not include spaces.  Ensure the Series returned as its index sorted.\n",
    "\n",
    "**Hints**:\n",
    "\n",
    "* Have a look at `value_counts` for a pandas `Series`.\n",
    "* You can iterate across the letters of a string using\n",
    "\n",
    "```\n",
    "some_string = 'abcdefg'\n",
    "for letter in some_string:\n",
    "    do somethign with letter...\n",
    "```\n",
    "* `str.lower` can be used to get the lower case version of a string\n",
    "\n",
    "(b). Use binary ufuncs, to do some interesting aggregates that can be computed directly from the object.\n",
    "For example, if we'd like to *reduce* an array with a particular operation, we can use the ``reduce`` method of any ufunc.\n",
    "A reduce repeatedly applies a given operation to the elements of an array until only a single result remains.\n",
    "\n",
    "For example, calling ``reduce`` on the ``add`` ufunc returns the sum of all elements in the array: `For x = np.arange(1, 6)`\n",
    "\n",
    "(i). reduce `x`\n",
    "\n",
    "(ii). add `x`\n",
    "\n",
    "(iii). multiply `x`\n",
    "\n",
    "(iv). accumulate `x`\n",
    "\n",
    "(v). compute additiona and accumulation in one row `x`\n",
    "\n",
    "(vi). compute multiplication and accumulation in one row `x`\n",
    "\n",
    "(V). do an outer product of `x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GOOD LUCK & `Be Not afraid of going slowly, be afraid of standing still` Old Chineese proverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
